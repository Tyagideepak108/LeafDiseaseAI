import streamlit as st
from PIL import Image
import json
import tensorflow as tf
from predict import predict_disease, preprocess_image
from gtts import gTTS
import io
import os
import pandas as pd
import datetime
try:
    import plotly.express as px
    import plotly.graph_objects as go
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False

# Custom DepthwiseConv2D to handle compatibility
class CompatibleDepthwiseConv2D(tf.keras.layers.DepthwiseConv2D):
    def __init__(self, *args, **kwargs):
        # Remove 'groups' parameter if present
        kwargs.pop('groups', None)
        super().__init__(*args, **kwargs)

# --- Class Names ---
sugarcane_class_names = sorted([
    "Banded Chlorosis", "Brown Spot", "BrownRust", "Dried Leaves", "Grassy shoot",
    "Healthy Leaves", "Pokkah Boeng", "Sett Rot", "smut", "Viral Disease", "Yellow Leaf" , "Red Stripe(viral Disease)"
])

other_class_names = sorted([
    "Pepper__bell___Bacterial_spot", "Pepper__bell___healthy",
    "Potato___Early_blight", "Potato___Late_blight", "Potato___healthy",
    "Tomato___Bacterial_spot", "Tomato___Early_blight", "Tomato___Late_blight",
    "Tomato___Leaf_Mold", "Tomato___Septoria_leaf_spot", "Tomato___Spider_mites Two-spotted_spider_mite",
    "Tomato___Target_Spot", "Tomato___Tomato_Yellow_Leaf_Curl_Virus",
    "Tomato___Tomato_mosaic_virus", "Tomato___healthy"
])

# --- Model and Info Paths ---
models_config = {
    "Sugarcane": {
        "model_path": "models/sugarcane_phase2_best.h5",
        "info_path": "sugercane_info.json",
        "class_names": sugarcane_class_names
    },
    "Other Crops": {
        "model_path": "models/other_crops_model_best.h5",
        "info_path": "other_diseases_info.json",
        "class_names": other_class_names
    }
}

# --- Page Config + CSS + Language Toggle + Labels ---

st.set_page_config(page_title="üå± Leaf Disease Detector", layout="wide", page_icon="üåø")

# function css 
def load_css(file_name):
    with open(file_name) as f:
        st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)

# Aur fir function ko call karo
load_css("style.css")

# --- Language & Navigation ---
if "lang" not in st.session_state:
    st.session_state.lang = "en"

# Initialize prediction history
if "prediction_history" not in st.session_state:
    st.session_state.prediction_history = []

# Modern Sidebar Navigation

st.sidebar.header("‚öôÔ∏è Settings")

# Language Toggle
st.sidebar.markdown("**üó£Ô∏è Language:**")
col1, col2 = st.sidebar.columns(2)
with col1:
    if st.button("üá¨üáß EN", key="lang_en"):
        st.session_state.lang = "en"
with col2:
    if st.button("üáÆüá≥ HI", key="lang_hi"):
        st.session_state.lang = "hi"

# --- Labels Dictionary ---
labels = {
    "en": {
        "title": "üåø Leaf Disease Detection App",
        "upload_header": "Upload an Image",
        "input_method": "Choose Input Method",
        "upload_button": "Upload Image",
        "webcam_button": "Use Webcam",
        "prediction_result": "Prediction Result",
        "disease_info": "Disease Information",
        "treatment_preventive": "Treatment & Preventive Measures",
        "organic": "Organic",
        "chemical": "Chemical",
        "preventive": "Preventive",
        "feedback_question": "Is this prediction correct?",
        "yes_button": "Yes üëç",
        "no_button": "No üëé",
        "feedback_form_title": "Please tell us what was wrong:",
        "submit_button": "Submit",
        "thanks_success": "Thanks! Feedback saved.",
        "dashboard_title": "Feedback Dashboard",
        "raw_data": "Raw Data",
        "correct_incorrect": "Correct vs Incorrect",
        "top_predictions": "Top Predicted Diseases",
        "no_feedback": "No feedback available yet.",
        "analyzing": "üîç Analyzing...",
        "not_confident": "‚ö†Ô∏è Model is not confident with this image. Please take a clearer image of the leaf for better results.",
        "select_details": "üëâ Select one to view details:",
        "no_details": "‚ÑπÔ∏è No details available for this disease.",
        "play_audio": "üîä Play Audio",
        "home": "Home",
        "dashboard": "Dashboard",
        "crop_select": "üåæ Select Crop Type",
        "feedback_title": "üìù Feedback",
        "history": "History",
        "prediction_history": "üìú Prediction History",
        "clear_history": "üóëÔ∏è Clear History",
        "no_history": "No predictions yet. Upload an image to start!",
        "batch_upload": "üìé Batch Upload",
        "upload_multiple": "Upload Multiple Images",
        "processing_images": "Processing images...",
        "batch_results": "Batch Processing Results",
        "analytics_dashboard": "üìä Analytics Dashboard",
        "total_predictions": "Total Predictions",
        "accuracy": "Accuracy",
        "avg_confidence": "Avg Confidence",
        "diseases_found": "Diseases Found",
        "trends": "üìà Trends",
        "crops": "üåæ Crops",
        "diseases": "ü¶† Diseases",
        "details": "üìä Details",
        "prediction_trends": "üìà Prediction Trends",
        "confidence_distribution": "üìä Confidence Distribution",
        "weekly_pattern": "üìÖ Weekly Pattern",
        "crop_analysis": "üåæ Crop Analysis",
        "crop_accuracy": "üéØ Crop-wise Accuracy",
        "disease_analysis": "ü¶† Disease Analysis",
        "disease_severity": "‚ö†Ô∏è Disease Severity (by frequency)",
        "detailed_analytics": "üìä Detailed Analytics",
        "filter_date": "Filter by date range",
        "filter_crop": "Filter by crop",
        "showing_records": "Showing",
        "records": "records",
        "export_csv": "üìæ Export Data as CSV",
        "download_csv": "Download CSV",
        "successful_predictions": "Successful Predictions",
        "made_by": "Developed with ‚ù§Ô∏è by Deepak Tyagi" # ADDED FOR FOOTER
    },
    "hi": {
        "title": "üåø ‡§™‡§§‡•ç‡§§‡•ã‡§Ç ‡§ï‡•Ä ‡§¨‡•Ä‡§Æ‡§æ‡§∞‡•Ä ‡§ï‡§æ ‡§™‡§§‡§æ ‡§≤‡§ó‡§æ‡§®‡•á ‡§µ‡§æ‡§≤‡§æ ‡§ê‡§™",
        "upload_header": "‡§è‡§ï ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞ ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç",
        "input_method": "‡§á‡§®‡§™‡•Å‡§ü ‡§µ‡§ø‡§ß‡§ø ‡§ö‡•Å‡§®‡•á‡§Ç",
        "upload_button": "‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞ ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç",
        "webcam_button": "‡§µ‡•á‡§¨‡§ï‡•à‡§Æ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç",
        "prediction_result": "‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§®‡•Å‡§Æ‡§æ‡§® ‡§ï‡§æ ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ",
        "disease_info": "‡§¨‡•Ä‡§Æ‡§æ‡§∞‡•Ä ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä",
        "treatment_preventive": "‡§â‡§™‡§ö‡§æ‡§∞ ‡§î‡§∞ ‡§®‡§ø‡§µ‡§æ‡§∞‡§ï ‡§â‡§™‡§æ‡§Ø",
        "organic": "‡§ú‡•à‡§µ‡§ø‡§ï",
        "chemical": "‡§∞‡§æ‡§∏‡§æ‡§Ø‡§®‡§ø‡§ï",
        "preventive": "‡§®‡§ø‡§µ‡§æ‡§∞‡§ï",
        "feedback_question": "‡§ï‡•ç‡§Ø‡§æ ‡§Ø‡§π ‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§®‡•Å‡§Æ‡§æ‡§® ‡§∏‡§π‡•Ä ‡§π‡•à?",
        "yes_button": "‡§π‡§æ‡§Å üëç",
        "no_button": "‡§®‡§π‡•Ä‡§Ç üëé",
        "feedback_form_title": "‡§ï‡•É‡§™‡§Ø‡§æ ‡§¨‡§§‡§æ‡§è‡§Ç ‡§ï‡§ø ‡§ï‡•ç‡§Ø‡§æ ‡§ó‡§≤‡§§ ‡§•‡§æ:",
        "submit_button": "‡§ú‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç",
        "thanks_success": "‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶! ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§∏‡§π‡•á‡§ú ‡§≤‡•Ä ‡§ó‡§à ‡§π‡•à‡•§",
        "dashboard_title": "‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§°‡•à‡§∂‡§¨‡•ã‡§∞‡•ç‡§°",
        "raw_data": "‡§ï‡§ö‡•ç‡§ö‡§æ ‡§°‡•á‡§ü‡§æ",
        "correct_incorrect": "‡§∏‡§π‡•Ä ‡§¨‡§®‡§æ‡§Æ ‡§ó‡§≤‡§§",
        "top_predictions": "‡§∂‡•Ä‡§∞‡•ç‡§∑ ‡§Ö‡§®‡•Å‡§Æ‡§æ‡§®‡§ø‡§§ ‡§¨‡•Ä‡§Æ‡§æ‡§∞‡§ø‡§Ø‡§æ‡§Å",
        "no_feedback": "‡§Ö‡§≠‡•Ä ‡§ï‡•ã‡§à ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§",
        "analyzing": "üîç ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à...",
        "not_confident": "‚ö†Ô∏è ‡§Æ‡•â‡§°‡§≤ ‡§á‡§∏ ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞ ‡§∏‡•á ‡§Ü‡§∂‡•ç‡§µ‡§∏‡•ç‡§§ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§ ‡§¨‡•á‡§π‡§§‡§∞ ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡§§‡•ç‡§§‡•á ‡§ï‡•Ä ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞ ‡§≤‡•á‡§Ç‡•§",
        "select_details": "üëâ ‡§µ‡§ø‡§µ‡§∞‡§£ ‡§¶‡•á‡§ñ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§ö‡•Å‡§®‡•á‡§Ç:",
        "no_details": "‚ÑπÔ∏è ‡§á‡§∏ ‡§¨‡•Ä‡§Æ‡§æ‡§∞‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•ã‡§à ‡§µ‡§ø‡§µ‡§∞‡§£ ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§",
        "play_audio": "üîä ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ö‡§≤‡§æ‡§è‡§Ç",
        "home": "‡§π‡•ã‡§Æ",
        "dashboard": "‡§°‡•à‡§∂‡§¨‡•ã‡§∞‡•ç‡§°",
        "crop_select": "üåæ ‡§´‡§∏‡§≤ ‡§ï‡§æ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§ö‡•Å‡§®‡•á‡§Ç",
        "feedback_title": "üìù ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ",
        "history": "‡§á‡§§‡§ø‡§π‡§æ‡§∏",
        "prediction_history": "üìú ‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§®‡•Å‡§Æ‡§æ‡§® ‡§á‡§§‡§ø‡§π‡§æ‡§∏",
        "clear_history": "üóëÔ∏è ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§∏‡§æ‡§´‡§º ‡§ï‡§∞‡•á‡§Ç",
        "no_history": "‡§Ö‡§≠‡•Ä ‡§§‡§ï ‡§ï‡•ã‡§à ‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§®‡•Å‡§Æ‡§æ‡§® ‡§®‡§π‡•Ä‡§Ç‡•§ ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞ ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç!",
        "batch_upload": "üìé ‡§¨‡•à‡§ö ‡§Ö‡§™‡§≤‡•ã‡§°",
        "upload_multiple": "‡§ï‡§à ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞‡•á‡§Ç ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç",
        "processing_images": "‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞‡•á‡§Ç ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç...",
        "batch_results": "‡§¨‡•à‡§ö ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó ‡§ï‡•á ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ",
        "analytics_dashboard": "üìä ‡§è‡§®‡§æ‡§≤‡§ø‡§ü‡§ø‡§ï‡•ç‡§∏ ‡§°‡•à‡§∂‡§¨‡•ã‡§∞‡•ç‡§°",
        "total_predictions": "‡§ï‡•Å‡§≤ ‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§®‡•Å‡§Æ‡§æ‡§®",
        "accuracy": "‡§∏‡§ü‡•Ä‡§ï‡§§‡§æ",
        "avg_confidence": "‡§î‡§∏‡§§ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø‡§§‡§æ",
        "diseases_found": "‡§∞‡•ã‡§ó ‡§Æ‡§ø‡§≤‡•á",
        "trends": "üìà ‡§∞‡•Å‡§ù‡§æ‡§®",
        "crops": "üåæ ‡§´‡§∏‡§≤‡•á‡§Ç",
        "diseases": "ü¶† ‡§∞‡•ã‡§ó",
        "details": "üìä ‡§µ‡§ø‡§µ‡§∞‡§£",
        "prediction_trends": "üìà ‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§®‡•Å‡§Æ‡§æ‡§® ‡§∞‡•Å‡§ù‡§æ‡§®",
        "confidence_distribution": "üìä ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø‡§§‡§æ ‡§µ‡§ø‡§§‡§∞‡§£",
        "weekly_pattern": "üìÖ ‡§∏‡§æ‡§™‡•ç‡§§‡§æ‡§π‡§ø‡§ï ‡§™‡•à‡§ü‡§∞‡•ç‡§®",
        "crop_analysis": "üåæ ‡§´‡§∏‡§≤ ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£",
        "crop_accuracy": "üéØ ‡§´‡§∏‡§≤-‡§µ‡§æ‡§∞ ‡§∏‡§ü‡•Ä‡§ï‡§§‡§æ",
        "disease_analysis": "ü¶† ‡§∞‡•ã‡§ó ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£",
        "disease_severity": "‚ö†Ô∏è ‡§∞‡•ã‡§ó ‡§ï‡•Ä ‡§ó‡§Ç‡§≠‡•Ä‡§∞‡§§‡§æ (‡§Ü‡§µ‡•É‡§§‡•ç‡§§‡§ø ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞)",
        "detailed_analytics": "üìä ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§è‡§®‡§æ‡§≤‡§ø‡§ü‡§ø‡§ï‡•ç‡§∏",
        "filter_date": "‡§¶‡§ø‡§®‡§æ‡§Ç‡§ï ‡§∏‡•Ä‡§Æ‡§æ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§´‡§º‡§ø‡§≤‡•ç‡§ü‡§∞ ‡§ï‡§∞‡•á‡§Ç",
        "filter_crop": "‡§´‡§∏‡§≤ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§´‡§º‡§ø‡§≤‡•ç‡§ü‡§∞ ‡§ï‡§∞‡•á‡§Ç",
        "showing_records": "‡§¶‡§ø‡§ñ‡§æ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç",
        "records": "‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§°",
        "export_csv": "üìæ ‡§°‡•á‡§ü‡§æ ‡§ï‡•ã CSV ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§®‡§ø‡§∞‡•ç‡§Ø‡§æ‡§§ ‡§ï‡§∞‡•á‡§Ç",
        "download_csv": "CSV ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç",
        "successful_predictions": "‡§∏‡§´‡§≤ ‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§®‡•Å‡§Æ‡§æ‡§®",
        "made_by": "‡§¶‡•Ä‡§™‡§ï ‡§§‡•ç‡§Ø‡§æ‡§ó‡•Ä ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‚ù§Ô∏è ‡§ï‡•á ‡§∏‡§æ‡§• " # ADDED FOR FOOTER
    }
}
L = labels[st.session_state.lang]

# Initialize current page with English labels to avoid reset
if "current_page" not in st.session_state:
    st.session_state.current_page = "home"  # Use key instead of label

# Navigation Menu
st.sidebar.markdown("---")
st.sidebar.markdown("**üìå Navigation**")

# Navigation buttons with consistent keys
navigation_items = [
    ("üè†", "home", L["home"]),
    ("üìä", "dashboard", L["dashboard"]),
    ("üìú", "history", L["history"]),
    ("üìã", "batch_upload", L["batch_upload"])
]

for icon, page_key, page_label in navigation_items:
    if st.sidebar.button(f"{icon} {page_label}", key=f"nav_{page_key}", use_container_width=True):
        st.session_state.current_page = page_key

# Map current page key to label for comparison
page_mapping = {
    "home": L["home"],
    "dashboard": L["dashboard"],
    "history": L["history"],
    "batch_upload": L["batch_upload"]
}

page = page_mapping[st.session_state.current_page]

# --- Function: TTS ---
def text_to_speech(text, lang):
    if not text:
        return None
    try:
        tts = gTTS(text, lang=lang)
        audio_bytes_io = io.BytesIO()
        tts.write_to_fp(audio_bytes_io)
        return audio_bytes_io
    except Exception as e:
        st.error(f"‚ùå Error generating audio: {e}")
        return None

# --- Function: Load Model ---
@st.cache_resource
def load_model(model_path, crop_name):
    try:
        # Custom objects for compatibility
        custom_objects = {
            'DepthwiseConv2D': CompatibleDepthwiseConv2D
        }
        return tf.keras.models.load_model(model_path, custom_objects=custom_objects, compile=False)
    except Exception as e:
        st.error(f"‚ùå Error loading model: {e}")
        return None



# --- HOME PAGE ---
if page == L["home"]:
    st.title(L["title"])



    # Sidebar crop selection
    st.sidebar.header(L["crop_select"])
    selected_crop = st.sidebar.selectbox(L["crop_select"], list(models_config.keys()))
    
    # Clear cache if crop changed
    if "current_crop" not in st.session_state:
        st.session_state.current_crop = selected_crop
    elif st.session_state.current_crop != selected_crop:
        st.cache_resource.clear()
        st.session_state.current_crop = selected_crop
    
    config = models_config[selected_crop]
    model = load_model(config["model_path"], selected_crop)  # Pass crop name for unique caching
    class_names = config["class_names"]

    # Load disease info JSON
    try:
        with open(config["info_path"], "r", encoding="utf-8") as f:
            disease_info = json.load(f)
    except Exception as e:
        st.error(f"‚ùå Error loading disease info: {e}")
        st.stop()

    # Image Input - Preserve image on language change
    if "uploaded_image" not in st.session_state:
        st.session_state.uploaded_image = None
    if "webcam_image" not in st.session_state:
        st.session_state.webcam_image = None
        
    st.header(L["upload_header"])
    upload_method = st.radio(L["input_method"], [L["upload_button"], L["webcam_button"]])
    image_input = None
    
    if upload_method == L["upload_button"]:
        uploaded = st.file_uploader(L["upload_button"], type=["jpg", "jpeg", "png"])
        if uploaded:
            st.session_state.uploaded_image = Image.open(uploaded)
            st.session_state.webcam_image = None
        if st.session_state.uploaded_image:
            image_input = st.session_state.uploaded_image
            st.image(image_input, caption=L["upload_button"], use_container_width=True)
            
    elif upload_method == L["webcam_button"]:
        cam_image = st.camera_input(L["webcam_button"])
        if cam_image:
            st.session_state.webcam_image = Image.open(cam_image)
            st.session_state.uploaded_image = None
        if st.session_state.webcam_image:
            image_input = st.session_state.webcam_image
            st.image(image_input, caption=L["webcam_button"], use_container_width=True)

    # ---- Prediction Logic ----
    final_pred = None
    final_conf = None

    if image_input and model:
        with st.spinner(L["analyzing"]):
            # Debug info
            st.write(f"üîç Using model for: {selected_crop}")
            # st.write(f"üìä Model expects {len(class_names)} classes")
            # st.write(f"üìã Model path: {config['model_path']}")
            
            # Verify model output matches class names
            if model is not None:
                try:
                    # Test prediction shape
                    test_shape = model.output_shape
                    expected_classes = test_shape[-1] if test_shape else "Unknown"
                    # st.write(f"ü§ñ Model output classes: {expected_classes}")
                    
                    if expected_classes != len(class_names):
                        st.error(f"‚ö†Ô∏è Model mismatch! Model has {expected_classes} outputs but {len(class_names)} class names provided.")
                        st.stop()
                except:
                    pass
            
            predicted_class, confidence, is_confident = predict_disease(image_input, model, class_names)

        if not is_confident:  # Show message to take better image
            st.warning(L["not_confident"])
            st.info("üí° Tips for better image: \n- Use good lighting \n- Focus on the leaf clearly \n- Avoid blurry images \n- Capture the diseased area properly")
            st.stop()  # Stop processing and don't show predictions
        else:
            final_pred, final_conf = predicted_class, confidence
            
            # Save to prediction history
            history_entry = {
                "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "crop": selected_crop,
                "disease": final_pred,
                "confidence": final_conf,
                "image": image_input.copy()  # Store a copy of the image
            }
            st.session_state.prediction_history.insert(0, history_entry)  # Add to beginning
            
            # Keep only last 10 predictions
            if len(st.session_state.prediction_history) > 10:
                st.session_state.prediction_history = st.session_state.prediction_history[:10]

        # --- Show Disease Info ---
        if final_pred:
            st.subheader(L["prediction_result"])
            
            # Display disease name based on language
            display_name = final_pred
            if st.session_state.lang == "hi":
                matched_info_temp = disease_info.get(final_pred)
                if matched_info_temp and matched_info_temp.get('hindi_name'):
                    display_name = matched_info_temp.get('hindi_name')
            
            confidence_text = "Confidence" if st.session_state.lang == "en" else "‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø‡§§‡§æ"
            
            st.markdown(
                f"<div style='border-radius:12px;padding:12px;margin-top:10px;"
                f"background-color:#1e1e2f;box-shadow:2px 2px 10px rgba(0,0,0,0.5);'>"
                f"<h4 style='color:#4CAF50;'>{display_name}</h4>"
                f"<p style='color:#ccc;'>{confidence_text}: {final_conf:.2f}%</p>"
                "</div>", unsafe_allow_html=True
            )

            matched_info = disease_info.get(final_pred)
            if matched_info:
                st.subheader(L["disease_info"])
                
                # Language-specific display
                if st.session_state.lang == "hi":
                    # Hindi mode - show only Hindi
                    hindi_name = matched_info.get('hindi_name', final_pred)
                    st.markdown(f"**‡§∞‡•ã‡§ó ‡§ï‡§æ ‡§®‡§æ‡§Æ:** {hindi_name}")
                    
                    hin_cause = matched_info.get("cause_hindi", "N/A")
                    st.markdown(f"**‡§ï‡§æ‡§∞‡§£:** {hin_cause}")
                    if st.button("üîä ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§∏‡•Å‡§®‡•á‡§Ç", key="hin_audio"):
                        audio_io = text_to_speech(hin_cause, 'hi')
                        if audio_io: st.audio(audio_io.getvalue(), format='audio/mp3')
                else:
                    # English mode - show only English
                    st.markdown(f"**Disease Name:** {final_pred}")
                    
                    eng_cause = matched_info.get("cause", "N/A")
                    st.markdown(f"**Cause:** {eng_cause}")
                    if st.button("üîä Play Audio", key="eng_audio"):
                        audio_io = text_to_speech(eng_cause, 'en')
                        if audio_io: st.audio(audio_io.getvalue(), format='audio/mp3')

                st.divider()
                st.subheader(L["treatment_preventive"])
                tab1, tab2, tab3 = st.tabs([f"üåø {L['organic']}", f"üß™ {L['chemical']}", f"üõ°Ô∏è {L['preventive']}"])
                
                # Get language-specific treatment data
                if st.session_state.lang == "hi":
                    organic_treatments = matched_info.get("organic_treatment", [])
                    chemical_treatments = matched_info.get("chemical_treatment", [])
                    preventive_measures = matched_info.get("preventive_measures", [])
                else:
                    organic_treatments = matched_info.get("organic_treatment_en", [])
                    chemical_treatments = matched_info.get("chemical_treatment_en", [])
                    preventive_measures = matched_info.get("preventive_measures_en", [])
                
                with tab1:
                    for step in organic_treatments:
                        st.markdown(f"- {step}")
                with tab2:
                    for step in chemical_treatments:
                        st.markdown(f"- {step}")
                with tab3:
                    for step in preventive_measures:
                        st.markdown(f"- {step}")
            else:
                st.warning(L["no_details"])

            # --- Feedback Section ---
            st.divider()
            st.header(L["feedback_title"])
            st.write(L["feedback_question"])

            # Save image for feedback
            if not os.path.exists("feedback_images"):
                os.makedirs("feedback_images")
            timestamp_str = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            image_filename = f"feedback_images/{final_pred}_{timestamp_str}.png"
            image_input.save(image_filename)

            col_yes, col_no = st.columns(2)
            if col_yes.button(L["yes_button"]):
                feedback_data = {
                    "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "prediction": final_pred,
                    "confidence": f"{final_conf:.2f}%",
                    "is_correct": "Yes",
                    "comment": "N/A",
                    "image_path": image_filename
                }
                pd.DataFrame([feedback_data]).to_csv(
                    "feedback.csv", mode='a', header=not os.path.exists("feedback.csv"), index=False
                )
                st.success(L["thanks_success"])

            if col_no.button(L["no_button"]):
                st.session_state.show_comment_box = True

            if st.session_state.get("show_comment_box"):
                with st.form("feedback_form"):
                    user_comment = st.text_area(L["feedback_form_title"])
                    submit = st.form_submit_button(L["submit_button"])
                    if submit:
                        feedback_data = {
                            "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                            "prediction": final_pred,
                            "confidence": f"{final_conf:.2f}%",
                            "is_correct": "No",
                            "comment": user_comment,
                            "image_path": image_filename
                        }
                        pd.DataFrame([feedback_data]).to_csv(
                            "feedback.csv", mode='a', header=not os.path.exists("feedback.csv"), index=False
                        )
                        st.success(L["thanks_success"])
                        st.session_state.show_comment_box = False
                        st.rerun()

# --- ANALYTICS DASHBOARD PAGE ---
elif page == L["dashboard"]:
    st.title(L["analytics_dashboard"])
    
    # Combine feedback data and prediction history
    feedback_exists = os.path.exists("feedback.csv")
    history_exists = len(st.session_state.prediction_history) > 0
    
    if not feedback_exists and not history_exists:
        st.info(L["no_feedback"])
    else:
        # Load and prepare data
        all_data = []
        
        # Add feedback data
        if feedback_exists:
            df_feedback = pd.read_csv("feedback.csv")
            df_feedback['source'] = 'feedback'
            # Add crop column if missing (for old data)
            if 'crop' not in df_feedback.columns:
                df_feedback['crop'] = 'Unknown'
            all_data.append(df_feedback)
        
        # Add prediction history
        if history_exists:
            history_df = pd.DataFrame(st.session_state.prediction_history)
            history_df['is_correct'] = 'Unknown'
            history_df['comment'] = 'N/A'
            history_df['image_path'] = 'N/A'
            history_df['source'] = 'history'
            # Rename columns to match feedback data
            history_df = history_df.rename(columns={'disease': 'prediction'})
            all_data.append(history_df[['timestamp', 'prediction', 'confidence', 'crop', 'is_correct', 'comment', 'source']])
        
        # Combine all data
        if all_data:
            combined_df = pd.concat(all_data, ignore_index=True)
            combined_df['timestamp'] = pd.to_datetime(combined_df['timestamp'])
            combined_df['date'] = combined_df['timestamp'].dt.date
            
            # Fix confidence column - convert to numeric
            combined_df['confidence'] = pd.to_numeric(combined_df['confidence'].astype(str).str.replace('%', ''), errors='coerce')
            
            # --- KEY METRICS ---
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("üìä Total Predictions", len(combined_df))
            
            with col2:
                if feedback_exists:
                    accuracy = len(combined_df[combined_df['is_correct']=='Yes']) / len(combined_df[combined_df['is_correct'].isin(['Yes', 'No'])]) * 100
                    st.metric("üéØ Accuracy", f"{accuracy:.1f}%")
                else:
                    st.metric("üéØ Accuracy", "N/A")
            
            with col3:
                avg_confidence = combined_df['confidence'].mean()
                st.metric("üìä Avg Confidence", f"{avg_confidence:.1f}%")
            
            with col4:
                unique_diseases = combined_df['prediction'].nunique()
                st.metric("ü¶† Diseases Found", unique_diseases)
            
            st.divider()
            
            # --- ANALYTICS TABS ---
            tab1, tab2, tab3, tab4 = st.tabs(["üìà Trends", "üåæ Crops", "ü¶† Diseases", "üìä Details"])
            
            with tab1:
                st.subheader("üìà Prediction Trends")
                
                # Daily predictions
                daily_counts = combined_df.groupby('date').size().reset_index(name='count')
                st.line_chart(daily_counts.set_index('date'))
                
                # Confidence distribution
                st.subheader("üìä Confidence Distribution")
                confidence_bins = pd.cut(combined_df['confidence'], bins=[0, 50, 70, 85, 100], labels=['Low (0-50%)', 'Medium (50-70%)', 'High (70-85%)', 'Very High (85-100%)'])
                st.bar_chart(confidence_bins.value_counts())
                
                # Weekly pattern
                combined_df['weekday'] = combined_df['timestamp'].dt.day_name()
                weekday_counts = combined_df['weekday'].value_counts()
                st.subheader("üìÖ Weekly Pattern")
                st.bar_chart(weekday_counts)
            
            with tab2:
                st.subheader("üåæ Crop Analysis")
                
                if 'crop' in combined_df.columns:
                    crop_counts = combined_df['crop'].value_counts()
                    st.bar_chart(crop_counts)
                    
                    # Crop-wise accuracy
                    if feedback_exists:
                        crop_accuracy = combined_df[combined_df['is_correct'].isin(['Yes', 'No'])].groupby('crop')['is_correct'].apply(lambda x: (x=='Yes').mean() * 100)
                        st.subheader("üéØ Crop-wise Accuracy")
                        st.bar_chart(crop_accuracy)
                else:
                    st.info("Crop data not available in older predictions")
            
            with tab3:
                st.subheader("ü¶† Disease Analysis")
                
                # Top diseases
                disease_counts = combined_df['prediction'].value_counts().head(10)
                st.bar_chart(disease_counts)
                
                # Disease severity (based on frequency)
                st.subheader("‚ö†Ô∏è Disease Severity (by frequency)")
                severity_data = disease_counts.head(5)
                for disease, count in severity_data.items():
                    severity = "High" if count > severity_data.mean() else "Medium" if count > severity_data.mean()/2 else "Low"
                    color = "üî¥" if severity == "High" else "üü°" if severity == "Medium" else "üü¢"
                    st.write(f"{color} **{disease}**: {count} cases ({severity} risk)")
            
            with tab4:
                st.subheader("üìä Detailed Analytics")
                
                # Filter options
                col_filter1, col_filter2 = st.columns(2)
                
                with col_filter1:
                    date_filter = st.date_input("Filter by date range", value=[combined_df['date'].min(), combined_df['date'].max()])
                
                with col_filter2:
                    if 'crop' in combined_df.columns:
                        crop_filter = st.multiselect("Filter by crop", combined_df['crop'].unique(), default=combined_df['crop'].unique())
                    else:
                        crop_filter = []
                
                # Apply filters
                filtered_df = combined_df.copy()
                if len(date_filter) == 2:
                    filtered_df = filtered_df[(filtered_df['date'] >= date_filter[0]) & (filtered_df['date'] <= date_filter[1])]
                if crop_filter and 'crop' in combined_df.columns:
                    filtered_df = filtered_df[filtered_df['crop'].isin(crop_filter)]
                
                # Show filtered data
                st.write(f"**Showing {len(filtered_df)} records**")
                # Only show columns that exist
                display_cols = ['timestamp', 'prediction', 'confidence', 'is_correct']
                if 'crop' in filtered_df.columns:
                    display_cols.insert(3, 'crop')
                st.dataframe(filtered_df[display_cols].sort_values('timestamp', ascending=False))
                
                # Export button
                if st.button("üíæ Export Data as CSV"):
                    csv = filtered_df.to_csv(index=False)
                    st.download_button(
                        label="Download CSV",
                        data=csv,
                        file_name=f"leaf_disease_analytics_{datetime.datetime.now().strftime('%Y%m%d')}.csv",
                        mime="text/csv"
                    )

# --- HISTORY PAGE ---
elif page == L["history"]:
    st.title(L["prediction_history"])
    
    if not st.session_state.prediction_history:
        st.info(L["no_history"])
    else:
        # Clear history button
        if st.button(L["clear_history"]):
            st.session_state.prediction_history = []
            st.success("History cleared!" if st.session_state.lang == "en" else "‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§∏‡§æ‡§´‡§º ‡§ï‡§∞ ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ!")
            st.rerun()
        
        st.write(f"**Total Predictions:** {len(st.session_state.prediction_history)}")
        
        # Display history in cards
        for i, entry in enumerate(st.session_state.prediction_history):
            with st.container():
                col1, col2 = st.columns([1, 2])
                
                with col1:
                    st.image(entry["image"], width=150)
                
                with col2:
                    st.markdown(f"**üïí Time:** {entry['timestamp']}")
                    st.markdown(f"**üåæ Crop:** {entry['crop']}")
                    st.markdown(f"**ü¶† Disease:** {entry['disease']}")
                    st.markdown(f"**üìä Confidence:** {entry['confidence']:.2f}%")
                
                st.divider()

# --- BATCH UPLOAD PAGE ---
elif page == L["batch_upload"]:
    st.title(L["batch_upload"])
    
    # Crop selection for batch processing
    st.sidebar.header(L["crop_select"])
    selected_crop = st.sidebar.selectbox(L["crop_select"], list(models_config.keys()), key="batch_crop")
    
    config = models_config[selected_crop]
    model = load_model(config["model_path"], selected_crop)
    class_names = config["class_names"]
    
    # Load disease info
    try:
        with open(config["info_path"], "r", encoding="utf-8") as f:
            disease_info = json.load(f)
    except Exception as e:
        st.error(f"‚ùå Error loading disease info: {e}")
        st.stop()
    
    # Multiple file upload
    uploaded_files = st.file_uploader(
        L["upload_multiple"], 
        type=["jpg", "jpeg", "png"], 
        accept_multiple_files=True
    )
    
    if uploaded_files and model:
        st.write(f"**Selected {len(uploaded_files)} images for processing**")
        
        # Process button
        if st.button(f"üöÄ Process {len(uploaded_files)} Images"):
            results = []
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, uploaded_file in enumerate(uploaded_files):
                status_text.text(f"{L['processing_images']} {i+1}/{len(uploaded_files)}")
                progress_bar.progress((i + 1) / len(uploaded_files))
                
                try:
                    image = Image.open(uploaded_file)
                    predicted_class, confidence, is_confident = predict_disease(image, model, class_names)
                    
                    results.append({
                        "filename": uploaded_file.name,
                        "image": image,
                        "prediction": predicted_class if is_confident else "Low Confidence",
                        "confidence": confidence if is_confident else 0,
                        "is_confident": is_confident
                    })
                except Exception as e:
                    results.append({
                        "filename": uploaded_file.name,
                        "image": None,
                        "prediction": "Error",
                        "confidence": 0,
                        "is_confident": False,
                        "error": str(e)
                    })
            
            status_text.text("‚úÖ Processing Complete!")
            progress_bar.empty()
            
            # Display results
            st.subheader(L["batch_results"])
            
            # Summary stats
            confident_predictions = sum(1 for r in results if r["is_confident"])
            st.metric("Successful Predictions", f"{confident_predictions}/{len(results)}")
            
            # Results in columns
            cols = st.columns(2)
            for i, result in enumerate(results):
                with cols[i % 2]:
                    if result["image"]:
                        st.image(result["image"], width=200)
                    
                    st.write(f"**File:** {result['filename']}")
                    
                    if result["is_confident"]:
                        # Get display name
                        display_name = result["prediction"]
                        if st.session_state.lang == "hi":
                            matched_info = disease_info.get(result["prediction"])
                            if matched_info and matched_info.get('hindi_name'):
                                display_name = matched_info.get('hindi_name')
                        
                        st.success(f"üåø **{display_name}**")
                        st.write(f"Confidence: {result['confidence']:.2f}%")
                    else:
                        st.warning("‚ö†Ô∏è Low confidence - unclear image")
                    
                    if "error" in result:
                        st.error(f"Error: {result['error']}")
                    
                    st.divider()

# --- FOOTER ---
# ==================================
footer_html = f"""
<div class="footer">
    <p>{L['made_by']} | <a href="https://github.com/Tyagideepak108" target="_blank">GitHub</a> | <a href="https://www.linkedin.com/in/tyagi-deepak/" target="_blank">LinkedIn</a></p>
</div>
"""
st.markdown(footer_html, unsafe_allow_html=True)

